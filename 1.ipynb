In [1]:
#Data Science Assignment : Using Formula
In [2]:
#importing libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import linear_model
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
import seaborn as sns
In [3]:
# Import Iris Dataset from sklearn 
from sklearn.datasets import load_iris
get_ipython().run_line_magic('matplotlib', 'inline')
In [4]:
iris=load_iris()
In [5]:
#creating dataframe
df=pd.DataFrame(data=iris.data,columns=iris.feature_names)
In [6]:
dff=pd.DataFrame(data=iris.target,columns=['species'])
In [7]:
def converter(specie):
    if specie==0:
        return 'setosa'
    elif specie==1:
        return 'versicolor'
    else:
        return 'virginica'
dff['species']=dff['species'].apply(converter)
df=pd.concat([df,dff],axis=1)
In [8]:
df.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 150 entries, 0 to 149
Data columns (total 5 columns):
sepal length (cm)    150 non-null float64
sepal width (cm)     150 non-null float64
petal length (cm)    150 non-null float64
petal width (cm)     150 non-null float64
species              150 non-null object
dtypes: float64(4), object(1)
memory usage: 5.9+ KB
In [9]:
sns.pairplot(df, hue= 'species')
Out[9]:
<seaborn.axisgrid.PairGrid at 0x17c97507908>

In [10]:
#for calculating the error of the model,we'll predict sepal length 
#then compare it with the actual sepal length given in our dataset

#linear reg object
reg=linear_model.LinearRegression()
#species->number dtype
df.drop('species',axis=1,inplace=True)
dff=pd.DataFrame(columns=['species'],data=iris.target)
df=pd.concat([df,dff],axis=1)
df
Out[10]:
sepal length (cm)	sepal width (cm)	petal length (cm)	petal width (cm)	species
0	5.1	3.5	1.4	0.2	0
1	4.9	3.0	1.4	0.2	0
2	4.7	3.2	1.3	0.2	0
3	4.6	3.1	1.5	0.2	0
4	5.0	3.6	1.4	0.2	0
5	5.4	3.9	1.7	0.4	0
6	4.6	3.4	1.4	0.3	0
7	5.0	3.4	1.5	0.2	0
8	4.4	2.9	1.4	0.2	0
9	4.9	3.1	1.5	0.1	0
10	5.4	3.7	1.5	0.2	0
11	4.8	3.4	1.6	0.2	0
12	4.8	3.0	1.4	0.1	0
13	4.3	3.0	1.1	0.1	0
14	5.8	4.0	1.2	0.2	0
15	5.7	4.4	1.5	0.4	0
16	5.4	3.9	1.3	0.4	0
17	5.1	3.5	1.4	0.3	0
18	5.7	3.8	1.7	0.3	0
19	5.1	3.8	1.5	0.3	0
20	5.4	3.4	1.7	0.2	0
21	5.1	3.7	1.5	0.4	0
22	4.6	3.6	1.0	0.2	0
23	5.1	3.3	1.7	0.5	0
24	4.8	3.4	1.9	0.2	0
25	5.0	3.0	1.6	0.2	0
26	5.0	3.4	1.6	0.4	0
27	5.2	3.5	1.5	0.2	0
28	5.2	3.4	1.4	0.2	0
29	4.7	3.2	1.6	0.2	0
...	...	...	...	...	...
120	6.9	3.2	5.7	2.3	2
121	5.6	2.8	4.9	2.0	2
122	7.7	2.8	6.7	2.0	2
123	6.3	2.7	4.9	1.8	2
124	6.7	3.3	5.7	2.1	2
125	7.2	3.2	6.0	1.8	2
126	6.2	2.8	4.8	1.8	2
127	6.1	3.0	4.9	1.8	2
128	6.4	2.8	5.6	2.1	2
129	7.2	3.0	5.8	1.6	2
130	7.4	2.8	6.1	1.9	2
131	7.9	3.8	6.4	2.0	2
132	6.4	2.8	5.6	2.2	2
133	6.3	2.8	5.1	1.5	2
134	6.1	2.6	5.6	1.4	2
135	7.7	3.0	6.1	2.3	2
136	6.3	3.4	5.6	2.4	2
137	6.4	3.1	5.5	1.8	2
138	6.0	3.0	4.8	1.8	2
139	6.9	3.1	5.4	2.1	2
140	6.7	3.1	5.6	2.4	2
141	6.9	3.1	5.1	2.3	2
142	5.8	2.7	5.1	1.9	2
143	6.8	3.2	5.9	2.3	2
144	6.7	3.3	5.7	2.5	2
145	6.7	3.0	5.2	2.3	2
146	6.3	2.5	5.0	1.9	2
147	6.5	3.0	5.2	2.0	2
148	6.2	3.4	5.4	2.3	2
149	5.9	3.0	5.1	1.8	2
150 rows × 5 columns

In [11]:
y=df['sepal length (cm)']
z=df['sepal width (cm)']
x=df.drop(axis=1,labels=['sepal length (cm)', 'sepal width (cm)'])
x
Out[11]:
petal length (cm)	petal width (cm)	species
0	1.4	0.2	0
1	1.4	0.2	0
2	1.3	0.2	0
3	1.5	0.2	0
4	1.4	0.2	0
5	1.7	0.4	0
6	1.4	0.3	0
7	1.5	0.2	0
8	1.4	0.2	0
9	1.5	0.1	0
10	1.5	0.2	0
11	1.6	0.2	0
12	1.4	0.1	0
13	1.1	0.1	0
14	1.2	0.2	0
15	1.5	0.4	0
16	1.3	0.4	0
17	1.4	0.3	0
18	1.7	0.3	0
19	1.5	0.3	0
20	1.7	0.2	0
21	1.5	0.4	0
22	1.0	0.2	0
23	1.7	0.5	0
24	1.9	0.2	0
25	1.6	0.2	0
26	1.6	0.4	0
27	1.5	0.2	0
28	1.4	0.2	0
29	1.6	0.2	0
...	...	...	...
120	5.7	2.3	2
121	4.9	2.0	2
122	6.7	2.0	2
123	4.9	1.8	2
124	5.7	2.1	2
125	6.0	1.8	2
126	4.8	1.8	2
127	4.9	1.8	2
128	5.6	2.1	2
129	5.8	1.6	2
130	6.1	1.9	2
131	6.4	2.0	2
132	5.6	2.2	2
133	5.1	1.5	2
134	5.6	1.4	2
135	6.1	2.3	2
136	5.6	2.4	2
137	5.5	1.8	2
138	4.8	1.8	2
139	5.4	2.1	2
140	5.6	2.4	2
141	5.1	2.3	2
142	5.1	1.9	2
143	5.9	2.3	2
144	5.7	2.5	2
145	5.2	2.3	2
146	5.0	1.9	2
147	5.2	2.0	2
148	5.4	2.3	2
149	5.1	1.8	2
150 rows × 3 columns

In [12]:
#training the model
x_train, x_test, y_train, y_test = train_test_split(y,z, test_size=0.2,random_state=101)
In [13]:
plt.scatter(x_train,y_train)
plt.title("LENGTH VS WIDTH")
plt.xlabel("Sepal length (cm)")
plt.ylabel("Sepal width (cm)")
Out[13]:
Text(0, 0.5, 'Sepal width (cm)')

In [14]:
x=x_train
y=y_train
mean_x=x.mean()
mean_y=y.mean()
#calculating B1 and B0
b1=np.divide(np.sum(np.multiply(np.subtract(x,mean_x),np.subtract(y,mean_y))),np.sum(np.square(np.subtract(x,mean_x))))
print("B1: ",b1)
b0=np.subtract(mean_y,np.multiply(b1,mean_x))
print("B0: ",b0)
B1:  -0.05834498788583135
B0:  3.418471054031162
In [15]:
#Y=b0+b1*X
prediction=b0+b1*x_test
prediction
#prediction will be compared to y_test for error
Out[15]:
33     3.097574
16     3.103408
43     3.126746
129    2.998387
50     3.010056
123    3.050898
68     3.056732
53     3.097574
146    3.050898
1      3.132581
147    3.039229
32     3.115077
31     3.103408
122    2.969215
127    3.062567
74     3.045063
88     3.091739
96     3.085905
42     3.161753
134    3.062567
80     3.097574
48     3.109243
90     3.097574
65     3.027560
97     3.056732
64     3.091739
93     3.126746
114    3.080070
25     3.126746
41     3.155919
Name: sepal length (cm), dtype: float64
In [16]:
rmse=np.sqrt(np.divide(np.sum(np.square(np.subtract(prediction,y_test))),x.size))
In [17]:
print("Root mean squared error is for sepal length vs sepal width is: ",rmse)
Root mean squared error is for sepal length vs sepal width is:  0.2561177665293032
In [18]:
#non linear curves

prediction=b0+b1*np.square(x_test)
In [19]:
rmse=np.sqrt(np.divide(np.sum(np.square(np.subtract(prediction,y_test))),x.size))
In [20]:
print("Root mean squared error is for sepal length vs sepal width is using non linear curve: ",rmse)
Root mean squared error is for sepal length vs sepal width is using non linear curve:  0.8454376369521435
In [ ]:
